{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import scipy.io as sio\n",
    "import h5py\n",
    "import numpy as np\n",
    "from os.path import join as oj\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)})\n",
    "import pandas as pd\n",
    "import torch\n",
    "sys.path.insert(1, oj(sys.path[0], '..'))  # insert parent path\n",
    "from tqdm import tqdm\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import decomposition\n",
    "import matplotlib.gridspec as grd\n",
    "from sklearn import neural_network\n",
    "from torch.nn import functional as F\n",
    "from torch import nn, optim\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "num_gpu = 1 if torch.cuda.is_available() else 0\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stringer_dset\n",
    "ims, resps, ims_val, resps_val = stringer_dset.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "G = models.get_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model = models.get_reg_model()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "0 loss 1.2036013071895424 lr 1e-11\n",
      "\tloss mse 1.2036013888888888\n",
      "\tloss reg 0.6945621371269226\n",
      "\tval loss mse 1.0336727941176471\n",
      "\tval loss reg 0.6905852854251862\n",
      "20 loss 1.1349286764705881 lr 1e-11\n",
      "40 loss 1.0494067810457517 lr 1e-11\n",
      "60 loss 1.0254953431372549 lr 1e-11\n",
      "80 loss 1.0218225490196078 lr 1e-11\n",
      "100 loss 1.354948611111111 lr 1e-12\n",
      "\tloss mse 1.354948611111111\n",
      "\tloss reg 0.7492066919803619\n",
      "\tval loss mse 1.1334281045751633\n",
      "\tval loss reg 0.7260875701904297\n",
      "120 loss 1.0028217320261439 lr 1e-12\n"
     ]
    }
   ],
   "source": [
    "import utils    \n",
    "    \n",
    "learning_rate = 1e-11\n",
    "lambda_reg = 0.1\n",
    "    \n",
    "out_dir = 'out'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "its = 10000\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "learning_rate = 1e-11 # 1e-12 works\n",
    "model = models.GenNet(G).to(device)\n",
    "optimizer = torch.optim.SGD(model.fc1.parameters(), \n",
    "                            lr=learning_rate)\n",
    "lambda_reg = 0.1\n",
    "divisor = 34 * 45 * resps.shape[0]\n",
    "\n",
    "print('training...')        \n",
    "for it in range(its):\n",
    "    # lr step down\n",
    "    if it == 100:\n",
    "        optimizer.param_groups[0]['lr'] *= 0.1\n",
    "    if it == 600:\n",
    "        optimizer.param_groups[0]['lr'] *= 0.5\n",
    "    if it == 1000:\n",
    "        optimizer.param_groups[0]['lr'] *= 0.25    \n",
    "    if it == 20000:\n",
    "        optimizer.param_groups[0]['lr'] *= 0.5    \n",
    "    if it == 50000:\n",
    "        optimizer.param_groups[0]['lr'] *= 0.5        \n",
    "    \n",
    "    ims_pred = model(resps)\n",
    "    loss = loss_fn(ims_pred, ims) + lambda_reg * 1 - utils.lay1_sim(reg_model, ims, ims_pred)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if it % 20 == 0:\n",
    "        print(it, 'loss', loss.detach().item() / divisor, 'lr', optimizer.param_groups[0]['lr'])\n",
    "    if torch.sum(model.fc1.weight.grad).detach().item() == 0:\n",
    "        print('zero grad!')\n",
    "        print('w', torch.sum(model.fc1.weight))    \n",
    "        break\n",
    "\n",
    "    if it % 100 == 0:\n",
    "        utils.save_ims(out_dir, ims_pred, ims, it, num_ims=50)\n",
    "        print('\\tloss mse', loss_fn(ims_pred, ims).detach().item() / divisor)\n",
    "        print('\\tloss reg', 1 - utils.lay1_sim(reg_model, ims_pred, ims).detach().item())\n",
    "        with torch.no_grad():\n",
    "            ims_pred_val = model(resps_val)\n",
    "            utils.save_ims(out_dir, ims_pred_val, ims_val, it, num_ims=50, val=True)\n",
    "            print('\\tval loss mse', loss_fn(ims_pred_val, ims_val).detach().item() / (34 * 45 * resps_val.shape[0]))\n",
    "            print('\\tval loss reg', 1 - utils.lay1_sim(reg_model, ims_pred_val, ims_val).detach().item())\n",
    "    if it % 1000 == 0:\n",
    "        torch.save(model.state_dict(), oj(out_dir, 'model_' + str(it) + '.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**generate random ims**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_ims():\n",
    "    batch_size = 25\n",
    "    latent_size = 100\n",
    "\n",
    "    fixed_noise = torch.randn(batch_size, latent_size, 1, 1).to(device)\n",
    "    print(fixed_noise.shape)\n",
    "    fake_images = G(fixed_noise)\n",
    "\n",
    "    fake_images_np = fake_images.cpu().detach().numpy()\n",
    "    print(fake_images_np.shape)\n",
    "    fake_images_np = fake_images_np.reshape(fake_images_np.shape[0], 34, 45)\n",
    "    # fake_images_np = fake_images_np.transpose((0, 2, 3, 1))\n",
    "    plt.figure(figsize=(4.5, 3.4), dpi=100)\n",
    "    R, C = 5, 5\n",
    "    for i in range(batch_size):\n",
    "        plt.subplot(R, C, i + 1)\n",
    "        plt.imshow(fake_images_np[i], interpolation='bilinear', cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(hspace=0, wspace=0, left=0)\n",
    "    plt.show()\n",
    "# generate_random_ims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as tmodels\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "vgg = tmodels.vgg19(pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(10, 1, 34, 45).to(device)\n",
    "list(vgg.modules())[2]\n",
    "reg_model = list(vgg.modules())[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000, device='cuda:0', grad_fn=<DotBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lay_sim(reg_model, im1, im2):\n",
    "    # grayscale to 3 channel\n",
    "    \n",
    "    im1 = im1.expand(-1, 3, -1, -1)\n",
    "    im2 = im2.expand(-1, 3, -1, -1)\n",
    "    \n",
    "    feat1 = reg_model(im1).reshape(1, -1) #flatten()\n",
    "    feat2 = reg_model(im2).reshape(1flatten()\n",
    "    feat1 = feat1 / feat1.norm()\n",
    "    feat2 = feat2 / feat2.norm()\n",
    "    return torch.dot(feat1, feat2)\n",
    "lay_sim(reg_model, x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]\n"
     ]
    }
   ],
   "source": [
    "mods = list(vgg.features.modules())[1: 4]\n",
    "mods[1].inplace = False\n",
    "torch.nn.Sequential(mods[0], mods[1], mods[2])\n",
    "# print(mods.in_place)\n",
    "print(mods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lay_sim(reg_model, x, x).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vgg.modules())[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
