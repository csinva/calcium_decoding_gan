{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import scipy.io as sio\n",
    "import h5py\n",
    "import numpy as np\n",
    "from os.path import join as oj\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)})\n",
    "import pandas as pd\n",
    "import torch\n",
    "sys.path.insert(1, oj(sys.path[0], '..'))  # insert parent path\n",
    "from tqdm import tqdm\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import decomposition\n",
    "import matplotlib.gridspec as grd\n",
    "from sklearn import neural_network\n",
    "from torch.nn import functional as F\n",
    "from torch import nn, optim\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stringer_dset import StringerDset\n",
    "num_gpu = 1 if torch.cuda.is_available() else 0\n",
    "device = 'cuda' # 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "sdset = StringerDset()\n",
    "\n",
    "\n",
    "# get gan\n",
    "gan_dir = '/accounts/projects/vision/chandan/gan/cifar100_dcgan_grayscale'\n",
    "sys.path.insert(1, gan_dir)\n",
    "\n",
    "# load the models\n",
    "from dcgan import *\n",
    "\n",
    "D = Discriminator_rect(ngpu=num_gpu).to(device)\n",
    "G = Generator_rect(ngpu=num_gpu).to(device)\n",
    "\n",
    "# load weights\n",
    "D.load_state_dict(torch.load(oj(gan_dir, 'weights_rect/netD_epoch_299.pth')))\n",
    "G.load_state_dict(torch.load(oj(gan_dir, 'weights_rect/netG_epoch_299.pth')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ims, resps) = sdset[:1000]\n",
    "# model = LinNet().to(device) \n",
    "\n",
    "# normalize data\n",
    "means = np.mean(ims, axis=0)\n",
    "stds = np.std(ims, axis=0) + 1e-8\n",
    "ims_norm = (ims - means) / stds\n",
    "\n",
    "ims = torch.Tensor(ims_norm).to(device)\n",
    "resps = torch.Tensor(resps).to(device)\n",
    "\n",
    "# trans = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenNet(nn.Module):\n",
    "    def __init__(self, G):\n",
    "        super(GenNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(11449, 100) # num_neurons to latent space\n",
    "        self.fc1.weight.data = 1e-3 * self.fc1.weight.data\n",
    "        self.fc1.bias.data = 1e-3 * self.fc1.bias.data\n",
    "        self.G = G.eval()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "#         print('latent', x[0, :20])\n",
    "        x = x.reshape(x.shape[0], x.shape[1], 1, 1)\n",
    "        im = self.G(x)\n",
    "        return im\n",
    "    \n",
    "class LinNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(11449, 34 * 45) # num_neurons to latent space\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = x.reshape(x.shape[0], 34, 45)\n",
    "        return x\n",
    "\n",
    "    \n",
    "def viz_ims(ims_pred, ims, num_ims=5):    \n",
    "    plt.figure(figsize=(num_ims * 1.2, 2), dpi=100)\n",
    "    R, C = 2, num_ims\n",
    "    for i in range(num_ims):\n",
    "        plt.subplot(R, C, i + 1)\n",
    "        plt.imshow(ims_pred[i].cpu().detach().numpy().reshape(34, 45), interpolation='bilinear', cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(hspace=0, wspace=0, left=0)\n",
    "    for i in range(num_ims):\n",
    "        plt.subplot(R, C, i + 1 + num_ims)\n",
    "        plt.imshow(ims[i].cpu().detach().numpy().reshape(34, 45), interpolation='bilinear', cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(hspace=0, wspace=0, left=0)\n",
    "    plt.show()\n",
    "    \n",
    "print('initializing...')\n",
    "model = GenNet(G).to(device)\n",
    "its = 10000\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "learning_rate = 1e-12 # 1e-12 works\n",
    "optimizer = torch.optim.SGD(model.fc1.parameters(), \n",
    "                            lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=100, \n",
    "                                           verbose=False, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08)\n",
    "num_ims = 8\n",
    "\n",
    "print('training...')        \n",
    "for it in range(its):\n",
    "    ims_pred = model(resps)\n",
    "    loss = loss_fn(ims_pred, ims)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if it % 10 == 0:\n",
    "        print(it, '\\tloss', loss.detach().item() / (34 * 45 * resps.shape[0]), 'lr', optimizer.param_groups[0]['lr'])\n",
    "    if torch.sum(model.fc1.weight.grad).detach().item() == 0:\n",
    "        print('zero grad!')\n",
    "        print('w', torch.sum(model.fc1.weight))    \n",
    "#     print('pred', ims_pred[0, :20])Ã¥\n",
    "    if it % 100 == 0:\n",
    "        viz_ims(ims_pred, ims, num_ims)\n",
    "    scheduler.step(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate random ims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_ims():\n",
    "    batch_size = 25\n",
    "    latent_size = 100\n",
    "\n",
    "    fixed_noise = torch.randn(batch_size, latent_size, 1, 1).to(device)\n",
    "    print(fixed_noise.shape)\n",
    "    fake_images = G(fixed_noise)\n",
    "\n",
    "    fake_images_np = fake_images.cpu().detach().numpy()\n",
    "    print(fake_images_np.shape)\n",
    "    fake_images_np = fake_images_np.reshape(fake_images_np.shape[0], 34, 45)\n",
    "    # fake_images_np = fake_images_np.transpose((0, 2, 3, 1))\n",
    "    plt.figure(figsize=(4.5, 3.4), dpi=100)\n",
    "    R, C = 5, 5\n",
    "    for i in range(batch_size):\n",
    "        plt.subplot(R, C, i + 1)\n",
    "        plt.imshow(fake_images_np[i], interpolation='bilinear', cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(hspace=0, wspace=0, left=0)\n",
    "    plt.show()\n",
    "generate_random_ims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
