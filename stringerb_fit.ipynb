{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import scipy.io as sio\n",
    "import h5py\n",
    "import numpy as np\n",
    "from os.path import join as oj\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)})\n",
    "import pandas as pd\n",
    "import torch\n",
    "sys.path.insert(1, oj(sys.path[0], '..'))  # insert parent path\n",
    "from tqdm import tqdm\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import decomposition\n",
    "import matplotlib.gridspec as grd\n",
    "from sklearn import neural_network\n",
    "from torch.nn import functional as F\n",
    "from torch import nn, optim\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stringer_dset import StringerDset\n",
    "num_gpu = 1 if torch.cuda.is_available() else 0\n",
    "device = 'cuda' # 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "sdset = StringerDset()\n",
    "\n",
    "\n",
    "# get gan\n",
    "gan_dir = '/accounts/projects/vision/chandan/gan/cifar100_dcgan_grayscale'\n",
    "sys.path.insert(1, gan_dir)\n",
    "\n",
    "# load the models\n",
    "from dcgan import *\n",
    "\n",
    "D = Discriminator_rect(ngpu=num_gpu).to(device)\n",
    "G = Generator_rect(ngpu=num_gpu).to(device)\n",
    "\n",
    "# load weights\n",
    "D.load_state_dict(torch.load(oj(gan_dir, 'weights_rect/netD_epoch_299.pth')))\n",
    "G.load_state_dict(torch.load(oj(gan_dir, 'weights_rect/netG_epoch_299.pth')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ims, resps) = sdset[:100]\n",
    "means = np.mean(ims, axis=0)\n",
    "stds = np.std(ims, axis=0) + 1e-8 # stds basically just magnifies stuff in the middle, no need to multiply it back\n",
    "ims_norm = (ims - means) / stds\n",
    "ims = torch.Tensor(ims_norm).to(device)\n",
    "# resps = (resps - np.mean(resps, axis=0)) / (np.std(resps, axis=0) + 1e-8)\n",
    "resps = torch.Tensor(resps).to(device)\n",
    "\n",
    "\n",
    "(ims_val, resps_val) = sdset[-100:]\n",
    "means_val = np.mean(ims_val, axis=0)\n",
    "stds_val = np.std(ims_val, axis=0) + 1e-8 # stds basically just magnifies stuff in the middle, no need to multiply it back\n",
    "ims_norm_val = (ims_val - means_val) / stds_val\n",
    "# resps_val = (resps_val - np.mean(resps_val, axis=0)) / (np.std(resps_val, axis=0) + 1e-8)\n",
    "ims_val = torch.Tensor(ims_norm_val).to(device)\n",
    "resps_val = torch.Tensor(resps_val).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = models.vgg19(pretrained=True).to(device)\n",
    "reg_model = list(vgg.features.modules())[1]\n",
    "\n",
    "# vgg \n",
    "def lay1_sim(reg_model, im1, im2):\n",
    "    # grayscale to 3 channel\n",
    "    \n",
    "    im1 = im1.expand(-1, 3, -1, -1)\n",
    "    im2 = im2.expand(-1, 3, -1, -1)\n",
    "    \n",
    "    feat1 = reg_model(im1).flatten()\n",
    "    feat2 = reg_model(im2).flatten()\n",
    "    feat1 = feat1 / feat1.norm()\n",
    "    feat2 = feat2 / feat2.norm()\n",
    "    return torch.dot(feat1, feat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "0 loss 1.2037367238562091 lr 1e-11\n",
      "\tloss mse 1.2037381535947713\n",
      "\tloss reg 0.6925430595874786\n",
      "\tval loss mse 24374585.01838235\n",
      "\tval loss reg 0.6907373666763306\n",
      "20 loss 0.9782524509803922 lr 1e-11\n",
      "40 loss 0.910654820261438 lr 1e-11\n",
      "60 loss 0.8689192197712419 lr 1e-11\n",
      "80 loss 0.857047079248366 lr 1e-11\n",
      "100 loss 0.8064471507352942 lr 1e-12\n",
      "\tloss mse 0.8064491421568627\n",
      "\tloss reg 0.5930293202400208\n",
      "\tval loss mse 21675660.38602941\n",
      "\tval loss reg 0.6757190227508545\n",
      "120 loss 0.7737780330882353 lr 1e-12\n",
      "140 loss 0.7664726307189542 lr 1e-12\n",
      "160 loss 0.7605632659313726 lr 1e-12\n",
      "180 loss 0.7552952920751634 lr 1e-12\n",
      "200 loss 0.7504363255718954 lr 1e-12\n",
      "\tloss mse 0.7504385212418301\n",
      "\tloss reg 0.5628479719161987\n",
      "\tval loss mse 22451666.36029412\n",
      "\tval loss reg 0.6801646649837494\n",
      "220 loss 0.7459669628267974 lr 1e-12\n",
      "240 loss 0.7417589869281046 lr 1e-12\n",
      "260 loss 0.7377313112745097 lr 1e-12\n",
      "280 loss 0.7339188112745098 lr 1e-12\n",
      "300 loss 0.7302235498366013 lr 1e-12\n",
      "\tloss mse 0.7302257965686274\n",
      "\tloss reg 0.5512708127498627\n",
      "\tval loss mse 22545583.180147056\n",
      "\tval loss reg 0.6807046830654144\n",
      "320 loss 0.7267105800653595 lr 1e-12\n",
      "340 loss 0.7233831699346405 lr 1e-12\n",
      "360 loss 0.7201725388071896 lr 1e-12\n",
      "380 loss 0.7170786866830066 lr 1e-12\n",
      "400 loss 0.7140642361111111 lr 1e-12\n",
      "\tloss mse 0.7140665849673202\n",
      "\tloss reg 0.5421655178070068\n",
      "\tval loss mse 22627910.845588237\n",
      "\tval loss reg 0.6812366545200348\n",
      "420 loss 0.7110512663398693 lr 1e-12\n",
      "440 loss 0.7081433823529412 lr 1e-12\n",
      "460 loss 0.7053378267973857 lr 1e-12\n",
      "480 loss 0.702640829248366 lr 1e-12\n",
      "500 loss 0.6999526654411765 lr 1e-12\n",
      "\tloss mse 0.6999550653594772\n",
      "\tloss reg 0.5342307090759277\n",
      "\tval loss mse 22721674.632352944\n",
      "\tval loss reg 0.681769073009491\n",
      "520 loss 0.6973288909313725 lr 1e-12\n",
      "540 loss 0.694772518382353 lr 1e-12\n",
      "560 loss 0.6923566176470588 lr 1e-12\n",
      "580 loss 0.6900529513888889 lr 1e-12\n",
      "600 loss 0.6877942197712418 lr 5e-13\n",
      "\tloss mse 0.687796670751634\n",
      "\tloss reg 0.5271322727203369\n",
      "\tval loss mse 22788372.242647056\n",
      "\tval loss reg 0.6821643710136414\n",
      "620 loss 0.6866210682189543 lr 5e-13\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c81d9f48456d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mims_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mims_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mims\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlambda_reg\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlay1_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mims_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2154\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2155\u001b[0m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2156\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2157\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class GenNet(nn.Module):\n",
    "    def __init__(self, G):\n",
    "        super(GenNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(11449, 100) # num_neurons to latent space\n",
    "        self.fc1.weight.data = 1e-3 * self.fc1.weight.data\n",
    "        self.fc1.bias.data = 1e-3 * self.fc1.bias.data\n",
    "        self.G = G.eval()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "#         print('latent', x[0, :20])\n",
    "        x = x.reshape(x.shape[0], x.shape[1], 1, 1)\n",
    "        im = self.G(x)\n",
    "        return im\n",
    "    \n",
    "class LinNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(11449, 34 * 45) # num_neurons to latent space\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = x.reshape(x.shape[0], 34, 45)\n",
    "        return x\n",
    "\n",
    "    \n",
    "def viz_ims(ims_pred, ims, num_ims=5):    \n",
    "    plt.figure(figsize=(num_ims * 1.2, 2), dpi=100)\n",
    "    R, C = 2, num_ims\n",
    "    for i in range(num_ims):\n",
    "        plt.subplot(R, C, i + 1)\n",
    "        plt.imshow(ims_pred[i].cpu().detach().numpy().reshape(34, 45), interpolation='bilinear', cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(hspace=0, wspace=0, left=0)\n",
    "    for i in range(num_ims):\n",
    "        plt.subplot(R, C, i + 1 + num_ims)\n",
    "        plt.imshow(ims[i].cpu().detach().numpy().reshape(34, 45), interpolation='bilinear', cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(hspace=0, wspace=0, left=0)\n",
    "    plt.show()\n",
    "\n",
    "def save_ims(ims_pred, ims, it, num_ims=5, val=False):      \n",
    "    suffix = '_val' if val else ''\n",
    "    \n",
    "    ims_save = np.empty((2 * num_ims, 1, 34, 45), dtype=np.float32)\n",
    "    ims = ims[:num_ims].cpu().detach().numpy()\n",
    "    ims -= np.min(ims, axis=0)\n",
    "    ims /= np.max(ims, axis=0)\n",
    "    ims_save[0::2] = ims\n",
    "    \n",
    "    ims_pred = ims_pred[:num_ims].cpu().detach().numpy()\n",
    "    ims_pred -= np.min(ims_pred, axis=0)\n",
    "    ims_pred /= np.max(ims_pred, axis=0)\n",
    "    ims_save[0::2] = ims\n",
    "    ims_save[1::2] = ims_pred\n",
    "    ims_save = torch.Tensor(ims_save)\n",
    "    vutils.save_image(ims_save,\n",
    "                '{}/{}_samples{}.png'.format(out_dir, it, suffix),\n",
    "                normalize=False, nrow=10)    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "out_dir = 'out'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "its = 10000\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "learning_rate = 1e-11 # 1e-12 works\n",
    "model = GenNet(G).to(device)\n",
    "optimizer = torch.optim.SGD(model.fc1.parameters(), \n",
    "                            lr=learning_rate)\n",
    "num_ims = 8\n",
    "lambda_reg = 0.1\n",
    "divisor = 34 * 45 * resps.shape[0]\n",
    "\n",
    "print('training...')        \n",
    "for it in range(its):\n",
    "    # lr step down\n",
    "    if it == 100:\n",
    "        optimizer.param_groups[0]['lr'] *= 0.1\n",
    "    if it == 600:\n",
    "        optimizer.param_groups[0]['lr'] *= 0.5\n",
    "    if it == 1000:\n",
    "        optimizer.param_groups[0]['lr'] *= 0.25    \n",
    "    if it == 20000:\n",
    "        optimizer.param_groups[0]['lr'] *= 0.5    \n",
    "    if it == 50000:\n",
    "        optimizer.param_groups[0]['lr'] *= 0.5        \n",
    "    \n",
    "    ims_pred = model(resps)\n",
    "    loss = loss_fn(ims_pred, ims) + lambda_reg * 1 - lay1_sim(reg_model, ims, ims_pred)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if it % 20 == 0:\n",
    "        print(it, 'loss', loss.detach().item() / divisor, 'lr', optimizer.param_groups[0]['lr'])\n",
    "    if torch.sum(model.fc1.weight.grad).detach().item() == 0:\n",
    "        print('zero grad!')\n",
    "        print('w', torch.sum(model.fc1.weight))    \n",
    "        break\n",
    "#     print('pred', ims_pred[0, :20])\n",
    "\n",
    "    if it % 100 == 0:\n",
    "#         viz_ims(ims_pred, ims, num_ims)\n",
    "        save_ims(ims_pred, ims, it, num_ims=50)\n",
    "        print('\\tloss mse', loss_fn(ims_pred, ims).detach().item() / divisor)\n",
    "        print('\\tloss reg', 1 - lay1_sim(reg_model, ims_pred, ims).detach().item())\n",
    "        with torch.no_grad():\n",
    "            ims_pred_val = model(resps_val)\n",
    "            save_ims(ims_pred_val, ims_val, it, num_ims=50, val=True)\n",
    "            print('\\tval loss mse', loss_fn(ims_pred_val, ims_val).detach().item() / (34 * 45 * resps_val.shape[0]))\n",
    "            print('\\tval loss reg', 1 - lay1_sim(reg_model, ims_pred_val, ims_val).detach().item())\n",
    "    if it % 1000 == 0:\n",
    "        torch.save(model.state_dict(), oj(out_dir, 'model_' + str(it) + '.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**generate random ims**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_ims():\n",
    "    batch_size = 25\n",
    "    latent_size = 100\n",
    "\n",
    "    fixed_noise = torch.randn(batch_size, latent_size, 1, 1).to(device)\n",
    "    print(fixed_noise.shape)\n",
    "    fake_images = G(fixed_noise)\n",
    "\n",
    "    fake_images_np = fake_images.cpu().detach().numpy()\n",
    "    print(fake_images_np.shape)\n",
    "    fake_images_np = fake_images_np.reshape(fake_images_np.shape[0], 34, 45)\n",
    "    # fake_images_np = fake_images_np.transpose((0, 2, 3, 1))\n",
    "    plt.figure(figsize=(4.5, 3.4), dpi=100)\n",
    "    R, C = 5, 5\n",
    "    for i in range(batch_size):\n",
    "        plt.subplot(R, C, i + 1)\n",
    "        plt.imshow(fake_images_np[i], interpolation='bilinear', cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(hspace=0, wspace=0, left=0)\n",
    "    plt.show()\n",
    "# generate_random_ims()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
